---
title: "Logistic Regression Model"
author: "Thomas Bahng"
date: "February 15, 2020"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(BaylorEdPsych)
```

* This file creates a logistic regression model using R
* It will train on train.csv output from relay_data_analysis.ipynb
* It will predict on test.csv output from relay_data_analysis.ipynb

## Read the data

```{r}
dftrain <- read.csv('train.csv')
dftest <- read.csv('test.csv')
# columns to keep
cols <- c('esent','eopenrate','eclickrate','avgorder','ordfreq','paperless','y')
dftrain <- dftrain[, cols]
dftest <- dftest[, cols]
```

## Logistic Regression Model

```{r}
# model
mod <- glm(y~., family = binomial(link = logit), data = dftrain)
summary(mod)
```

## Coefficients in Plain Odds

```{r}
exp(coef(mod)) # converted log-odds to odds
```

Significant drivers of retention in plain odds: 

* the coefficient on esent (0.184) was 1.202, suggesting that for each unit increase in the number of emails sent to customer, the odds of retention increases by 1.2:1 or about 20%.

* the coefficient on paperless (0.494) was 1.64, suggesting that paperless subscriptions increases the odds of retention by 1.64:1 or about 64%.

## Confidence Interval in Plain Odds

```{r}
exp(confint(mod)) # converted log-odds to odds
```

*The 95% confidence interval of the odds shows that ordfreq overlaps with the odds of 1:1 and spans a large uncertainty width of 1.085 +- 0.458, which also means that log-odds overlaps with 0. As these intervals are only based on a sample, the true population value may or may not reside in these particular intervals.*

## Pseudo R-squared

```{r}
PseudoR2(mod)
```

*Pseudo R-squared measured at 0.60 per Cox.Snell, can loosely be interpreted as the proportion of variance in retained accounted for by the predictor variables*

## Predict Test Set

```{r}
# predict test set
preds <- predict(mod, newdata = dftest, type = 'response')
preds <- ifelse(preds > 0.5, 1, 0)
```

## Confusion Matrix and Accuracy

```{r}
# confusion matrix
(cmat <- table(preds, dftest$y))
# accuracy
acc <- round(sum(diag(cmat)) / sum(cmat),2)
```

Accuracy of predictions made on test set measured at: `r acc`

## Precision and Recall

```{r}
prec_1 <- 4476 / (4476 + 454)
rec_1 <- 4476 / (4476 + 650)
prec_0 <- 4703 / (4703 + 650)
rec_0 <- 4703 / (4703 + 454)
f_1 <- (2*prec_1*rec_1) / (prec_1 + rec_1)
f_0 <- (2*prec_0*rec_0) / (prec_0 + rec_0)
```

* Precision class=1: `r prec_1`
* Recall class=1: `r rec_1`
* Precision class=0: `r prec_0`
* Recall class=0: `r rec_0`
* f-measure class=1: `r f_1`
* f_measure class=0: `r f_0`