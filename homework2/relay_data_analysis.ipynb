{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36564bitbasecondacd90c988128e4e428ceb9fe9a1123e59",
   "display_name": "Python 3.6.5 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Using Retail Relay Data\n",
    "\n",
    "This notebook will demonstrate predicting customer retention using logistic regression.\n",
    "\n",
    "Assignment Questions:\n",
    "\n",
    "1. Use the Relay data to develop a model to predict customer retention. You may use logistic regression to predict the variable “retained.” You can use any combination of the independent variables available in the data to obtain a model\n",
    "with the best predictive ability and usability. You are free to use different transformations and combinations of the independent variables. Be aware that there is no “magic bullet” to finding the ideal model. You will have to go through multiple iterations.\n",
    "\n",
    "2. Split the data into test and train. Generally, 70% of the data is used to train the model and a hold out sample of 30% is used to test the accuracy of the model.\n",
    "\n",
    "3. Create the first model with all the variables that can be used in the given data set. Interpret the coefficients in a real-world sense.\n",
    "\n",
    "4. Once you obtain the best model that you can find, predict retention in the test data. You will use the logistic regression coefficients obtained from the train data to do this. This new variable will be the predicted value of retained.\n",
    "\n",
    "5. Calculate the hit rate. This can be calculated as % of matches between the value of the variable “retained” and the predicted value of “retained” in the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "plt.rc('font', size = 14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns \n",
    "sns.set(style = 'white')\n",
    "sns.set(style = 'whitegrid', color_codes = True)\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"Relay_Data.xlsx\"\n",
    "df = pd.read_excel(fname, sheet_name=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4514dce5d1cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# top 5 observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# top 5 observations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom 5 observations\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns and their data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset contains 30801 observations of 15 variables\n",
    "* The target variable is called 'retained'\n",
    "* There are several variables that may not be useful to include in the regression model itself such as:\n",
    "    * custid (ID), created (Datetime), firstorder (Datetime), lastorder (Datetime)\n",
    "    * firstorder and lastorder should be Datetime format, but they come encoded as 'object' type.\n",
    "    * Although these may not end up in the regression model, it might be good to explore the data visually using these variables in conjunction with the target variable 'retained'. \n",
    "* Some preprocessing and exploration is definitely in scope given the data.\n",
    "* There are two 'object' type variables 'favday' and 'city', which may be useful to include in the regression model. These should be one-hot-encoded to create dummy variables for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "* **custid**:       Computer generated ID to identify customers throughout the database\n",
    "* **retained**:     1, if customer is assumed to be active, 0 = otherwise\n",
    "* **created**:\t    Date when the contact was created in the database - when the customer joined\n",
    "* **firstorder**:\tDate when the customer placed first order\n",
    "* **lastorder**:\tDate when the customer placed last order\n",
    "* **esent**:    \tNumber of emails sent\n",
    "* **eopenrate**:\tNumber of emails opened divided by number of emails sent\n",
    "* **eclickrate**:\tNumber of emails clicked divided by number of emails sent\n",
    "* **avgorder**: \tAverage order size for the customer\n",
    "* **ordfreq**:  \tNumber of orders divided by customer tenure\n",
    "* **paperless**:\t1 if customer subscribed for paperless communication (only online)\n",
    "* **refill**:   \t1 if customer subscribed for automatic refill\n",
    "* **doorstep**: \t1 if customer subscribed for doorstep delivery\n",
    "* **favday**:   \tCustomer's favorite delivery day\n",
    "* **city**:     \tCity where the customer resides in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate 'custid' is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {:d} total observations\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {:d} unique customer ids\".format(len(set(df.custid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer ID is in fact not the unique identifier of this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of missing values by column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are exactly 20 missing values in each of these variables:\n",
    "* 'custid','created','firstorder','lastorder'\n",
    "* The following observations contain missing values in these variables\n",
    "* For the purposes of this demonstration, these observations will still be used for logistic regression modeling as the target variable and proposed independent variables do not contain any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = df[df.isnull().any(axis = 1)]\n",
    "missing_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicate observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df.loc[df.duplicated(keep = False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset does not contain any duplicated observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of unique values by variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col + ' ' + str(df[col].nunique()) for col in list(df.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following independent variables are categorical in nature:\n",
    "* 'paperless' - binary\n",
    "* 'refill 2' - binary\n",
    "* 'doorstep' - binary\n",
    "* 'favday' - categorical 7-levels\n",
    "* 'city' - categorical 4-levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Class Imbalance in Target Variable 'retained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['retained'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24472 / (24472+6329)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a class imbalance in the Target Variable 'retained'. 80% of observations are 'retained' = 1; 20% of observations are 'retained' = 0. Due to the class imbalance, it will be necessary to perform resampling to balance the classes prior to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Average Values by Class\n",
    "* For each target class label, compute the average value of each independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for modeling\n",
    "these_vars = ['retained','esent','eopenrate','eclickrate','avgorder','ordfreq']\n",
    "df[these_vars].groupby('retained').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On average:\n",
    "* 'esent' (number of emails sent to customer) is substantially higher for retained customers than for non-retained customers.\n",
    "    * **Retained customers were sent 34 emails on average versus 4 emails for non-retained customers**\n",
    "* 'eopenrate' (emails opened) and 'eclickrate' (emails clicked) are slightly higher as well for retained customers than for non-retained customers.\n",
    "* 'avgorder' (average order size) is similar for retained customers and non-retained customers. This doesn't appear to be a very distinguishing factor.\n",
    "* 'ordfreq' (ratio of number of orders to customer tenure) is also similar between retained and non-retained customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Distributions of Variables by Retained and Non-Retained Customers\n",
    "* For each of the variables ('esent','eopenrate','eclickrate','avgorder','ordfreq') assess how different the distributions are for retained vs. non-retained customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Emails Sent by 'retained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = 'esent', x = 'retained', data = df, palette='colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the visualization, there does appear to be a significant difference in the number of emails sent to the customer between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Emails Opened by 'retained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = 'eopenrate', x = 'retained', data = df, palette = 'colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the visualization, there does appear to be a significant difference in the number of emails opened between classes, but also exhibits a lot of uncertainty due to the overlapping interquartile ranges of the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Emails Clicked by 'retained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = 'eclickrate', x = 'retained', data = df, palette = 'colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the visualization, there does appear to be a significant difference in the number of emails clicked between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Order Size by 'retained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = 'avgorder', x = 'retained', data = df, palette = 'colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the visualization, there doesn't appear to be a significant difference in average order size between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Frequency by 'retained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = 'ordfreq', x = 'retained', data = df, palette = 'colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the visualization, there doesn't appear to be a significant difference in order frequency between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm differences between classes using T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "varlist = ['esent','eopenrate','eclickrate','avgorder','ordfreq']\n",
    "for var in varlist:\n",
    "    t, p = stats.ttest_ind(\n",
    "        df.loc[df.retained == 0, var],\n",
    "        df.loc[df.retained == 1, var]\n",
    "    )\n",
    "    print(\"variable:\", var)\n",
    "    print(\"t statistic:\", t)\n",
    "    print(\"p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The t-tests show that the mean differences in the variables 'esent', 'eopenrate', and 'eclickrate' are significantly different from zero between retained and non-retained customers. \n",
    "* Although the p-values show statistical significance in each case, there is a large contrast between the t statistic for 'esent' compared to the others. \n",
    "* This may informally indicate that 'esent' is the biggest factor in distinguising retained versus non-retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new variable 'orddiff'\n",
    "* This is the difference in days between first order and last order date\n",
    "* This may be a proxy variable for customer tenure, which isn't available in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in days between first order and last order date\n",
    "orddiff = pd.to_datetime(df['lastorder'], errors = 'coerce') - pd.to_datetime(df['firstorder'], errors = 'coerce')\n",
    "df['orddiff'] = orddiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orddiff summary for whole dataset\n",
    "df.orddiff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orddiff summary for non-retained customers\n",
    "df.loc[df.retained == 0, 'orddiff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orddiff summary for retained customers\n",
    "df.loc[df.retained == 1, 'orddiff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p = stats.ttest_ind(\n",
    "    df.loc[df.retained == 0, 'orddiff'].values.astype(np.int32),\n",
    "    df.loc[df.retained == 1, 'orddiff'].values.astype(np.int32)\n",
    ")\n",
    "print(t, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is not a huge difference between retained and non-retained customers concerning the variable 'orddiff' (proxy for *tenure*), but it appears that retained customers had on average more days between their first order and last order.\n",
    "* T-test shows that the mean difference between classes are not significantly different from zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare categorical variables: 'paperless' vs 'retained'\n",
    "* 1 if customer subscribed for paperless communication (only online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import pylab\n",
    "# categorical independent variables are:\n",
    "# ('paperless','refill','doorstep','favday','city')\n",
    "\n",
    "# function to generate categorical analysis\n",
    "def getcat(lst):\n",
    "    myvars = lst\n",
    "    mosaic(df, myvars)\n",
    "    pylab.show()\n",
    "    print(pd.crosstab(df[myvars[0]], df[myvars[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getcat(['paperless','retained'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The majority of retained customers subscribed for paperless communication (only online), however for non-retained customers, the majority did not subscribe to paperless communication. This variable appears to distinguish the classes fairly well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare categorical variables: 'refill' vs 'retained'\n",
    "* 1 if customer subscribed for automatic refill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getcat(['refill','retained'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The majority of retained customers did not subscribe for automatic refill. This variable doesn't appear to distinguish the classes very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare categorical variables: 'doorstep' vs 'retained'\n",
    "* 1 if customer subscribed for doorstep delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getcat(['doorstep','retained'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The majority of both retained and non-retained customers did not subscribe for doorstep delivery. This variable doesn't appear to distinguish the classes very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare categorical variables: 'favday' vs 'retained'\n",
    "* Customer's favorite delivery day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getcat(['favday','retained'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mondays and Tuesdays were the most preferred days for both retained and non-retained customers. Weekends were the least preferred days for customers. This variable doesn't appear to distinguish the classes very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare categorical variables: 'city' vs 'retained'\n",
    "* City where the customer resides in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getcat(['city','retained'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This variable doesn't appear to distinguish the classes very well as the proportions by city do not contast much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Variables used for modeling\n",
    "* For simplicity, the target variable 'retained' will be renamed to 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename class label variable to 'y'\n",
    "df = df.rename(columns = {'retained': 'y'}) # rename column\n",
    "# columns to keep\n",
    "keep_cols = ['y','esent','eopenrate','eclickrate','avgorder','ordfreq','paperless']\n",
    "data_final = df[keep_cols]\n",
    "data_final.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Multi-Collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Inflation Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# independent variables\n",
    "X = data_final.loc[:, data_final.columns != 'y']\n",
    "variables = list(range(X.shape[1]))\n",
    "vif = [variance_inflation_factor(X.iloc[:, variables].values, ix) for ix in range(X.iloc[:, variables].shape[1])]\n",
    "pd.DataFrame({'variable': X.columns, 'vif': vif})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There exists some moderate correlation between the independent variables, but all appear to be within acceptable ranges for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-sampling using SMOTE\n",
    "* up-sample the non-retained observations using the SMOTE algorithm(Synthetic Minority Oversampling Technique). At a high level, SMOTE:\n",
    "\n",
    "    * Works by creating synthetic samples from the minor class (complex parts) instead of creating copies.\n",
    "    * Randomly choosing one of the k-nearest-neighbors and using it to create a similar, but randomly tweaked, new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# independent variables\n",
    "X = data_final.loc[:, data_final.columns != 'y']\n",
    "# target variable\n",
    "y = data_final.loc[:, data_final.columns == 'y'].values.ravel()\n",
    "# set seed for over-sampling\n",
    "os = SMOTE(random_state=0) \n",
    "# train-test split; test set size = 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "columns = X_train.columns\n",
    "os_data_X, os_data_y = os.fit_sample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data = os_data_X, columns = columns)\n",
    "os_data_y = pd.DataFrame(data = os_data_y, columns = ['y'])\n",
    "# check results from over-sampling\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of non-retained customers in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"Number of retained customers in oversampled data\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"Proportion of non-retained customers in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"Proportion of retained customers in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Over-Sampled Data to File\n",
    "* save training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.concat([os_data_X, os_data_y], axis=1)\n",
    "dat.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Logistic Regression Model (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='warn', n_jobs=None, penalty='l2',\n                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n                   warm_start=False)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size = 0.3, random_state = 0)\n",
    "logreg = LogisticRegression() # negate regularization effect that sklearn applies to logistic regression\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the test set results and calculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy of logistic regression classifier on test set: 0.89\n"
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([-3.57134328])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.1835137 ,  0.0063645 ,  0.01378084, -0.00329958, -0.06070313,\n         0.47667634]])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write training and test data to csv\n",
    "dat = X_train\n",
    "dat['y'] = y_train\n",
    "dat.to_csv(\"train.csv\")\n",
    "dat = X_test\n",
    "dat['y'] = y_test\n",
    "dat.to_csv(\"test.csv\")"
   ]
  }
 ]
}